{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d0b67a3",
      "metadata": {
        "id": "3d0b67a3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Chan Thong Fong\\OneDrive - National University of Singapore\\Documents\\Y4S1\\DSA4213\\DSA4213-SEC-Fillings-Chatbot\\venv\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm, trange\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\"\\nfrom google.colab import userdata\\n\\n# Load secrets from Colab and set them as environment variables\\nos.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\\nos.environ['QDRANT_URL'] = userdata.get('QDRANT_URL')\\nos.environ['QDRANT_API_KEY'] = userdata.get('QDRANT_API_KEY')\\n\""
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import uuid\n",
        "import time\n",
        "import requests\n",
        "import gc\n",
        "import json\n",
        "from typing import List, Dict, Tuple\n",
        "from collections import defaultdict\n",
        "from bs4 import BeautifulSoup, NavigableString\n",
        "\n",
        "# External libraries (install via pip)\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from qdrant_client import QdrantClient, models\n",
        "from qdrant_client.models import Distance, VectorParams, PointStruct\n",
        "from openai import OpenAI\n",
        "\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "'''\n",
        "from google.colab import userdata\n",
        "\n",
        "# Load secrets from Colab and set them as environment variables\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "os.environ['QDRANT_URL'] = userdata.get('QDRANT_URL')\n",
        "os.environ['QDRANT_API_KEY'] = userdata.get('QDRANT_API_KEY')\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f3255ddf",
      "metadata": {
        "id": "f3255ddf"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# PART 1: CONFIGURATION & SETUP\n",
        "# ============================================================================\n",
        "\n",
        "class Config:\n",
        "    \"\"\"Configuration class for API keys and model settings\"\"\"\n",
        "\n",
        "    # API Keys - SET THESE BEFORE RUNNING\n",
        "    QDRANT_URL = os.getenv(\"QDRANT_URL\")\n",
        "    QDRANT_API_KEY = os.getenv(\"QDRANT_API_KEY\")\n",
        "    OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "    # SEC EDGAR Configuration\n",
        "    SEC_HEADERS = {'User-Agent': 'SEC10Q-RAG-System research@example.com'}\n",
        "    CIK_MAP_URL = 'https://www.sec.gov/files/company_tickers.json'\n",
        "\n",
        "    # Model Configuration\n",
        "    EMBEDDING_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"  # 384 dimensions\n",
        "    LLM_MODEL = \"gpt-4o\"\n",
        "\n",
        "    # Collection Configuration\n",
        "    COLLECTION_NAME = \"sec_filings_10q_GOLDEN_BENCHMARK\"\n",
        "    VECTOR_SIZE = 384  # Dimension for all-MiniLM-L6-v2\n",
        "\n",
        "    # Chunking Configuration\n",
        "    CHUNK_SIZE = 800  # Characters per chunk\n",
        "    CHUNK_OVERLAP = 200  # Overlap between chunks\n",
        "\n",
        "    # Retrieval Configuration\n",
        "    TOP_K = 5  # Number of chunks to retrieve\n",
        "\n",
        "    # Company Tickers\n",
        "    TICKERS = ['NVDA', 'AAPL', 'MSFT', 'AMZN', 'META', 'GOOGL', 'TSLA', 'ORCL', 'JPM', 'AMD']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "bfb2dfc0",
      "metadata": {
        "id": "bfb2dfc0"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# PART 2: DOCUMENT LOADING\n",
        "# ============================================================================\n",
        "\n",
        "class SECDocumentLoader:\n",
        "    \"\"\"Handles fetching and parsing of SEC 10-Q filings\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def get_recent_10q_metadata(ticker: str, num_filings: int = 4) -> List[Dict[str, str]]:\n",
        "        \"\"\"\n",
        "        Fetches the metadata (links, dates, etc.) for the latest N 10-Q filings.\n",
        "        Does NOT fetch the actual HTML content.\n",
        "\n",
        "        Args:\n",
        "            ticker: The company ticker (e.g., 'AAPL')\n",
        "            num_filings: The number of recent 10-Q filings to fetch\n",
        "\n",
        "        Returns:\n",
        "            List of metadata dictionaries\n",
        "        \"\"\"\n",
        "        print(f\"  → Fetching CIK for ticker: {ticker}...\")\n",
        "\n",
        "        # Get CIK mapping\n",
        "        response = requests.get(Config.CIK_MAP_URL, headers=Config.SEC_HEADERS)\n",
        "        response.raise_for_status()\n",
        "        company_data = response.json()\n",
        "\n",
        "        # Find CIK\n",
        "        cik = None\n",
        "        company_name = None\n",
        "        for company in company_data.values():\n",
        "            if company['ticker'] == ticker.upper():\n",
        "                cik = str(company['cik_str']).zfill(10)\n",
        "                company_name = company['title']\n",
        "                break\n",
        "\n",
        "        if not cik:\n",
        "            raise ValueError(f\"Ticker '{ticker}' not found in SEC CIK mapping.\")\n",
        "\n",
        "        print(f\"  → Found CIK: {cik} ({company_name})\")\n",
        "\n",
        "        # Fetch submission history\n",
        "        submissions_url = f\"https://data.sec.gov/submissions/CIK{cik}.json\"\n",
        "        time.sleep(0.1)  # Rate limiting\n",
        "        response = requests.get(submissions_url, headers=Config.SEC_HEADERS)\n",
        "        response.raise_for_status()\n",
        "        submissions = response.json()\n",
        "\n",
        "        # Find latest N 10-Q filings metadata\n",
        "        filings_metadata = []\n",
        "        for i, form in enumerate(submissions['filings']['recent']['form']):\n",
        "            if form == '10-Q':\n",
        "                accession_number = submissions['filings']['recent']['accessionNumber'][i]\n",
        "                primary_document = submissions['filings']['recent']['primaryDocument'][i]\n",
        "                filing_date = submissions['filings']['recent']['filingDate'][i]\n",
        "\n",
        "                accession_number_clean = accession_number.replace('-', '')\n",
        "\n",
        "                # Construct the filing URL\n",
        "                filing_url = (\n",
        "                    f\"https://www.sec.gov/Archives/edgar/data/{cik}/\"\n",
        "                    f\"{accession_number_clean}/{primary_document}\"\n",
        "                )\n",
        "\n",
        "                metadata = {\n",
        "                    'ticker': ticker.upper(),\n",
        "                    'company_name': company_name,\n",
        "                    'filing_date': filing_date,\n",
        "                    'cik': cik,\n",
        "                    'filing_url': filing_url\n",
        "                }\n",
        "                filings_metadata.append(metadata)\n",
        "\n",
        "                if len(filings_metadata) >= num_filings:\n",
        "                    break\n",
        "\n",
        "        if not filings_metadata:\n",
        "            raise ValueError(f\"No recent 10-Q filings found for ticker '{ticker}'.\")\n",
        "\n",
        "        print(f\"  → Found {len(filings_metadata)} recent 10-Q filing metadata entries.\")\n",
        "        return filings_metadata\n",
        "\n",
        "    @staticmethod\n",
        "    def get_filing_html(filing_url: str) -> str:\n",
        "        \"\"\"Fetches the HTML content for a single filing URL.\"\"\"\n",
        "        time.sleep(0.1)  # Rate limiting\n",
        "        response = requests.get(filing_url, headers=Config.SEC_HEADERS)\n",
        "        response.raise_for_status()\n",
        "        return response.text\n",
        "\n",
        "    @staticmethod\n",
        "    def _normalize_header_text(text: str) -> str:\n",
        "        \"\"\"Normalizes header text to standard format\"\"\"\n",
        "        text = text.strip().upper()\n",
        "\n",
        "        # Match \"PART I\" or \"PART II\"\n",
        "        part_match = re.search(r'^\\s*(PART\\s+I{1,2})', text)\n",
        "        if part_match:\n",
        "            return re.sub(r'\\s+', ' ', part_match.group(1))\n",
        "\n",
        "        # Match \"ITEM 1\", \"ITEM 1A\", etc.\n",
        "        item_match = re.search(r'^\\s*(ITEM\\s+\\d[A-Z]?)', text)\n",
        "        if item_match:\n",
        "            return re.sub(r'\\s+', ' ', item_match.group(1))\n",
        "\n",
        "        return None\n",
        "\n",
        "    @staticmethod\n",
        "    def _parse_html_table(table_tag) -> str:\n",
        "        \"\"\"Converts HTML table to Markdown format\"\"\"\n",
        "        markdown_rows = []\n",
        "\n",
        "        for tr in table_tag.find_all('tr'):\n",
        "            cells = [\" \".join(cell.get_text(strip=True).split())\n",
        "                    for cell in tr.find_all(['td', 'th'])]\n",
        "            if any(cells):\n",
        "                markdown_rows.append(cells)\n",
        "\n",
        "        if not markdown_rows:\n",
        "            return \"\"\n",
        "\n",
        "        md_output = []\n",
        "        header = markdown_rows[0]\n",
        "        md_output.append(\"| \" + \" | \".join(header) + \" |\")\n",
        "        md_output.append(\"| \" + \" | \".join(['---'] * len(header)) + \" |\")\n",
        "\n",
        "        for row in markdown_rows[1:]:\n",
        "            while len(row) < len(header):\n",
        "                row.append(\"\")\n",
        "            row = row[:len(header)]\n",
        "            md_output.append(\"| \" + \" | \".join(row) + \" |\")\n",
        "\n",
        "        return \"\\n\" + \"\\n\".join(md_output) + \"\\n\"\n",
        "\n",
        "    @classmethod\n",
        "    def parse_10q(cls, html_content: str) -> Dict:\n",
        "        \"\"\"Parses HTML content into structured dictionary\"\"\"\n",
        "        # --- KEY CHANGE ---\n",
        "        # Use 'lxml' for better memory efficiency\n",
        "        soup = BeautifulSoup(html_content, 'lxml')\n",
        "\n",
        "        potential_headers = soup.find_all(['p', 'b', 'strong', 'div'])\n",
        "\n",
        "        doc_headers = []\n",
        "        for header in potential_headers:\n",
        "            text = header.get_text(strip=True)\n",
        "            if len(text) > 100:\n",
        "                continue\n",
        "\n",
        "            normalized_key = cls._normalize_header_text(text)\n",
        "            if normalized_key:\n",
        "                if not header.find_parent('a'):\n",
        "                    doc_headers.append({'tag': header, 'key': normalized_key})\n",
        "\n",
        "        if not doc_headers:\n",
        "            return {}\n",
        "\n",
        "        parsed_data = defaultdict(lambda: defaultdict(str))\n",
        "        current_part_key = None\n",
        "\n",
        "        for i, header_info in enumerate(doc_headers):\n",
        "            current_key = header_info['key']\n",
        "\n",
        "            if 'PART' in current_key:\n",
        "                current_part_key = current_key\n",
        "                continue\n",
        "\n",
        "            if 'ITEM' in current_key:\n",
        "                if not current_part_key:\n",
        "                    current_part_key = \"PART I\"\n",
        "\n",
        "                start_node = header_info['tag']\n",
        "                end_node = doc_headers[i + 1]['tag'] if i + 1 < len(doc_headers) else None\n",
        "\n",
        "                content_parts = []\n",
        "                element = start_node.next_element\n",
        "\n",
        "                while element and element != end_node:\n",
        "                    if isinstance(element, NavigableString):\n",
        "                        if not element.find_parent('table'):\n",
        "                            text = element.strip()\n",
        "                            if text:\n",
        "                                content_parts.append(text)\n",
        "                    elif element.name == 'table':\n",
        "                        if not element.find_parent('table'):\n",
        "                            table_markdown = cls._parse_html_table(element)\n",
        "                            if table_markdown:\n",
        "                                content_parts.append(table_markdown)\n",
        "\n",
        "                    element = element.next_element\n",
        "\n",
        "                full_content = \"\\n\".join(content_parts)\n",
        "                clean_content = re.sub(r'\\n{3,}', '\\n\\n', full_content).strip()\n",
        "\n",
        "                parsed_data[current_part_key][current_key] = clean_content\n",
        "\n",
        "        return {part: dict(items) for part, items in parsed_data.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cbff8d1",
      "metadata": {
        "id": "2cbff8d1"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# PART 3: TEXT CHUNKING & EMBEDDING\n",
        "# ============================================================================\n",
        "class DocumentProcessor:\n",
        "    \"\"\"\n",
        "    Processes documents into chunks using LangChain's splitter\n",
        "    and then embeds them in batches.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, embedding_model_name: str = Config.EMBEDDING_MODEL):\n",
        "        \"\"\"Initialize with embedding model and LangChain text splitter\"\"\"\n",
        "        print(f\"\\n Loading embedding model: {embedding_model_name}\")\n",
        "        self.model = SentenceTransformer(embedding_model_name)\n",
        "        print(f\"   ✓ Model loaded (dimension: {self.model.get_sentence_embedding_dimension()})\")\n",
        "\n",
        "        # Initialize LangChain's splitter\n",
        "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=Config.CHUNK_SIZE,\n",
        "            chunk_overlap=Config.CHUNK_OVERLAP,\n",
        "            length_function=len,\n",
        "            add_start_index=False, # Simpler metadata\n",
        "        )\n",
        "        print(f\"   ✓ Initialized RecursiveCharacterTextSplitter (chunk: {Config.CHUNK_SIZE}, overlap: {Config.CHUNK_OVERLAP})\")\n",
        "\n",
        "    def generate_document_chunks(self, parsed_data: Dict, metadata: Dict,\n",
        "                                 embed_batch_size: int = 1024):\n",
        "        \"\"\"\n",
        "        Processes parsed 10-Q data using LangChain's splitter,\n",
        "        then YIELDS chunk points one by one after batch-embedding.\n",
        "        \"\"\"\n",
        "\n",
        "        # Convert the parsed dict into a list of LangChain Document objects\n",
        "        all_docs = []\n",
        "        for part, items in parsed_data.items():\n",
        "            for item, content in items.items():\n",
        "                if not content:\n",
        "                    continue\n",
        "\n",
        "                # Create a metadata dict for *this specific document*\n",
        "                # before it gets chunked.\n",
        "                doc_metadata = {\n",
        "                    'ticker': metadata['ticker'],\n",
        "                    'company_name': metadata['company_name'],\n",
        "                    'filing_date': metadata['filing_date'],\n",
        "                    'filing_url': metadata['filing_url'],\n",
        "                    'part': part,\n",
        "                    'item': item\n",
        "                }\n",
        "\n",
        "                doc = Document(\n",
        "                    page_content=content,\n",
        "                    metadata=doc_metadata\n",
        "                )\n",
        "                all_docs.append(doc)\n",
        "\n",
        "        if not all_docs:\n",
        "            return # Stop the generator\n",
        "\n",
        "        # Split all documents at once using the LangChain splitter\n",
        "        print(f\"     → Splitting {len(all_docs)} high-level 'Items' into smaller chunks...\")\n",
        "        chunked_docs = self.text_splitter.split_documents(all_docs)\n",
        "        print(f\"     → Generated {len(chunked_docs)} chunks\")\n",
        "\n",
        "        text_batch = []\n",
        "        metadata_batch = []\n",
        "\n",
        "        # Consume the list one chunk at a time\n",
        "        for chunk in chunked_docs:\n",
        "            text_batch.append(chunk.page_content)\n",
        "            # The splitter automatically copies metadata to each chunk\n",
        "            metadata_batch.append(chunk.metadata)\n",
        "\n",
        "            # If batch is full, process it\n",
        "            if len(text_batch) >= embed_batch_size:\n",
        "                # 1. Embed the entire batch in one call\n",
        "                embeddings = self.model.encode(text_batch, show_progress_bar=False)\n",
        "\n",
        "                # 2. Yield each point from the processed batch\n",
        "                for txt, emb, meta in zip(text_batch, embeddings, metadata_batch):\n",
        "                    # The metadata (meta) already contains everything\n",
        "                    # from the doc_metadata we built above\n",
        "                    payload = {\n",
        "                        'text': txt,\n",
        "                        **meta # Unpack all metadata keys (ticker, item, part, etc.)\n",
        "                    }\n",
        "                    yield PointStruct(\n",
        "                        id=str(uuid.uuid4()),\n",
        "                        vector=emb.tolist(),\n",
        "                        payload=payload\n",
        "                    )\n",
        "\n",
        "                # 3. Reset the batch\n",
        "                text_batch = []\n",
        "                metadata_batch = []\n",
        "\n",
        "        if text_batch:\n",
        "            # 1. Embed the final batch\n",
        "            embeddings = self.model.encode(text_batch, show_progress_bar=False)\n",
        "\n",
        "            # 2. Yield each point\n",
        "            for txt, emb, meta in zip(text_batch, embeddings, metadata_batch):\n",
        "                payload = {\n",
        "                    'text': txt,\n",
        "                    **meta\n",
        "                }\n",
        "                yield PointStruct(\n",
        "                    id=str(uuid.uuid4()),\n",
        "                    vector=emb.tolist(),\n",
        "                    payload=payload\n",
        "                )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "80bed17c",
      "metadata": {
        "id": "80bed17c"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# PART 4: QDRANT VECTOR DATABASE\n",
        "# ============================================================================\n",
        "\n",
        "from qdrant_client import models\n",
        "\n",
        "class QdrantManager:\n",
        "    \"\"\"Manages Qdrant vector database operations\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize Qdrant client\"\"\"\n",
        "        print(f\"\\nConnecting to Qdrant Cloud...\")\n",
        "        self.client = QdrantClient(\n",
        "            url=Config.QDRANT_URL,\n",
        "            api_key=Config.QDRANT_API_KEY\n",
        "        )\n",
        "        print(f\"   ✓ Connected to Qdrant\")\n",
        "\n",
        "    def create_collection(self, collection_name: str = Config.COLLECTION_NAME,\n",
        "                         vector_size: int = Config.VECTOR_SIZE):\n",
        "        \"\"\"Create or recreate collection AND set up payload indexes\"\"\"\n",
        "        print(f\"\\n Setting up collection: {collection_name}\")\n",
        "\n",
        "        # Check if collection exists\n",
        "        collections = self.client.get_collections().collections\n",
        "        exists = any(col.name == collection_name for col in collections)\n",
        "\n",
        "        if exists:\n",
        "            print(f\"   ⚠ Collection exists, recreating...\")\n",
        "            self.client.delete_collection(collection_name)\n",
        "\n",
        "        # Create collection\n",
        "        self.client.create_collection(\n",
        "            collection_name=collection_name,\n",
        "            vectors_config=models.VectorParams( # Use models.VectorParams\n",
        "                size=vector_size,\n",
        "                distance=models.Distance.COSINE # Use models.Distance\n",
        "            )\n",
        "        )\n",
        "        print(f\"   ✓ Collection created\")\n",
        "\n",
        "        print(f\"   → Creating payload index for 'ticker'...\")\n",
        "        self.client.create_payload_index(\n",
        "            collection_name=collection_name,\n",
        "            field_name=\"ticker\",\n",
        "            field_schema=models.PayloadSchemaType.KEYWORD\n",
        "        )\n",
        "        print(f\"   → Creating payload index for 'item'...\")\n",
        "        self.client.create_payload_index(\n",
        "            collection_name=collection_name,\n",
        "            field_name=\"item\",\n",
        "            field_schema=models.PayloadSchemaType.KEYWORD\n",
        "        )\n",
        "        print(f\"   ✓ Payload indexes created.\")\n",
        "\n",
        "    def upsert_documents(self, points_generator,\n",
        "                        collection_name: str = Config.COLLECTION_NAME,\n",
        "                        batch_size: int = 2048) -> int:\n",
        "        \"\"\"\n",
        "        Uploads document chunks from a generator in batches.\n",
        "\n",
        "        Args:\n",
        "            points_generator: A generator that yields PointStructs\n",
        "            collection_name: Name of the collection\n",
        "            batch_size: Number of points to upload at once\n",
        "\n",
        "        Returns:\n",
        "            Total number of chunks uploaded\n",
        "        \"\"\"\n",
        "        print(f\" Uploading chunks to Qdrant in batches of {batch_size}...\")\n",
        "\n",
        "        batch = []\n",
        "        count = 0\n",
        "\n",
        "        for point in points_generator:\n",
        "            batch.append(point)\n",
        "\n",
        "            if len(batch) >= batch_size:\n",
        "                self.client.upsert(\n",
        "                    collection_name=collection_name,\n",
        "                    points=batch,\n",
        "                    wait=False # Added for speed\n",
        "                )\n",
        "                count += len(batch)\n",
        "                print(f\"     → Uploaded {count} chunks so far...\")\n",
        "                batch = [] # Reset batch\n",
        "\n",
        "        # Upload any remaining points\n",
        "        if batch:\n",
        "            self.client.upsert(\n",
        "                collection_name=collection_name,\n",
        "                points=batch,\n",
        "                wait=False # Added for speed\n",
        "            )\n",
        "            count += len(batch)\n",
        "\n",
        "        print(f\"  ✓ All chunks uploaded for this document. Total: {count}\")\n",
        "        return count\n",
        "\n",
        "    def search(self, query_vector: List[float],\n",
        "              collection_name: str = Config.COLLECTION_NAME,\n",
        "              limit: int = Config.TOP_K,\n",
        "              filter_dict: Dict = None) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        Search for similar documents\n",
        "\n",
        "        Args:\n",
        "            query_vector: Embedded query vector\n",
        "            collection_name: Name of the collection\n",
        "            limit: Number of results to return\n",
        "            filter_dict: Optional filter (e.g., {\"ticker\": \"AAPL\"})\n",
        "\n",
        "        Returns:\n",
        "            List of search results with scores and payloads\n",
        "        \"\"\"\n",
        "\n",
        "        qdrant_filter = None\n",
        "        if filter_dict:\n",
        "            qdrant_filter = models.Filter(\n",
        "                must=[\n",
        "                    models.FieldCondition(\n",
        "                        key=key,\n",
        "                        match=models.MatchValue(value=value)\n",
        "                    )\n",
        "                    for key, value in filter_dict.items()\n",
        "                ]\n",
        "            )\n",
        "\n",
        "        results = self.client.search(\n",
        "            collection_name=collection_name,\n",
        "            query_vector=query_vector,\n",
        "            limit=limit,\n",
        "            query_filter=qdrant_filter,\n",
        "            with_payload=True\n",
        "        )\n",
        "\n",
        "        return [\n",
        "            {\n",
        "                'score': result.score,\n",
        "                'payload': result.payload\n",
        "            }\n",
        "            for result in results\n",
        "        ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8471b72b",
      "metadata": {
        "id": "8471b72b"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# PART 5: RAG QUERY PIPELINE\n",
        "# ============================================================================\n",
        "class ManualRAGEngine:\n",
        "    \"\"\"\n",
        "    This is the manual RAG query engine that replaces the buggy\n",
        "    LangChainRAGEngine. It performs the RAG steps manually\n",
        "    using the components we've already built.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, document_processor: 'DocumentProcessor', qdrant_manager: 'QdrantManager'):\n",
        "        \"\"\"\n",
        "        Initialize the engine with the processor (for embeddings)\n",
        "        and the manager (for search).\n",
        "        \"\"\"\n",
        "        print(\"\\n Initializing Manual RAG Query Engine...\")\n",
        "\n",
        "        # 1. Get the embedding model from the document processor\n",
        "        #    (the one that is already loaded)\n",
        "        self.embedding_model = document_processor.model\n",
        "        print(\"   ✓ Using existing embedding model from DocumentProcessor\")\n",
        "\n",
        "        # 2. Get the Qdrant client from the Qdrant manager\n",
        "        self.qdrant_manager = qdrant_manager\n",
        "        print(\"   ✓ Using existing QdrantManager for search\")\n",
        "\n",
        "        # 3. Initialize the LLM\n",
        "        self.llm = ChatOpenAI(\n",
        "            model=Config.LLM_MODEL,\n",
        "            api_key=Config.OPENAI_API_KEY\n",
        "        )\n",
        "        print(\"   ✓ Initialized ChatOpenAI LLM\")\n",
        "\n",
        "        # 4. Create a prompt template (we can still use this part)\n",
        "        template = \"\"\"You are a helpful financial analyst assistant. Your role is to answer questions about SEC 10-Q filings based ONLY on the provided context.\n",
        "- Base your answer strictly on the provided context from SEC filings\n",
        "- Cite specific sections (e.g., \"According to Item 1A...\") when referencing information\n",
        "- If the answer is not in the context, clearly state that\n",
        "\n",
        "Context:\n",
        "<context>\n",
        "{context}\n",
        "</context>\n",
        "\n",
        "Question: {input}\n",
        "\n",
        "Answer:\"\"\"\n",
        "        self.prompt = ChatPromptTemplate.from_template(template)\n",
        "        print(\"   ✓ Manual RAG Engine ready.\")\n",
        "\n",
        "\n",
        "    def _format_context(self, search_results: List[Dict]) -> str:\n",
        "        \"\"\"Helper function to format the retrieved contexts\"\"\"\n",
        "        context_str = \"\"\n",
        "        for i, result in enumerate(search_results, 1):\n",
        "            payload = result.get('payload', {})\n",
        "            text = payload.get('text', 'No text found')\n",
        "            item = payload.get('item', 'N/A')\n",
        "            ticker = payload.get('ticker', 'N/A')\n",
        "            context_str += f\"Source {i} ({ticker} - {item}):\\n\\\"{text}\\\"\\n\\n\"\n",
        "        return context_str.strip()\n",
        "\n",
        "\n",
        "    def query(self, question: str, ticker_filter: str = None):\n",
        "        \"\"\"\n",
        "        Query the indexed filings using the manual retrieval and generation.\n",
        "        \"\"\"\n",
        "        print(f\"\\n Processing query with Manual Engine: '{question}'\")\n",
        "\n",
        "        # 1. Manually embed the query\n",
        "        print(\"   → Manually embedding query...\")\n",
        "        query_vector = self.embedding_model.encode(question).tolist()\n",
        "\n",
        "        # 2. Manually create the filter\n",
        "        filter_dict = None\n",
        "        if ticker_filter:\n",
        "            print(f\"   → Applying ticker filter: {ticker_filter}\")\n",
        "            filter_dict = {\"ticker\": ticker_filter}\n",
        "\n",
        "        # 3. Manually search Qdrant\n",
        "        print(\"   → Manually searching Qdrant...\")\n",
        "        search_results = self.qdrant_manager.search(\n",
        "            query_vector=query_vector,\n",
        "            limit=Config.TOP_K,\n",
        "            filter_dict=filter_dict\n",
        "        )\n",
        "\n",
        "        if not search_results:\n",
        "            return {'answer': 'No relevant context was found in the documents to answer this question.', 'sources': []}\n",
        "\n",
        "        # 4. Manually format the prompt\n",
        "        print(\"   → Formatting context and building prompt...\")\n",
        "        formatted_context = self._format_context(search_results)\n",
        "\n",
        "        # We use the prompt template to create the final message\n",
        "        final_prompt_message = self.prompt.format_messages(\n",
        "            context=formatted_context,\n",
        "            input=question\n",
        "        )\n",
        "\n",
        "        # 5. Manually invoke the LLM\n",
        "        print(\"   → Sending prompt to LLM...\")\n",
        "        llm_response = self.llm.invoke(final_prompt_message)\n",
        "        answer = llm_response.content\n",
        "\n",
        "        # 6. Format sources to match the expected output\n",
        "        sources = []\n",
        "        for i, result in enumerate(search_results, 1):\n",
        "            sources.append({\n",
        "                'ticker': result['payload'].get('ticker'),\n",
        "                'company': result['payload'].get('company_name'),\n",
        "                'item': result['payload'].get('item'),\n",
        "                'part': result['payload'].get('part'),\n",
        "                'filing_date': result['payload'].get('filing_date'),\n",
        "                'score': result['score'] # We get the real score now\n",
        "            })\n",
        "\n",
        "        return {\n",
        "            'answer': answer,\n",
        "            'sources': sources\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "9b12c056",
      "metadata": {
        "id": "9b12c056"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# PART 6: MAIN PIPELINE ORCHESTRATOR\n",
        "# ============================================================================\n",
        "\n",
        "class SECFilingRAGPipeline:\n",
        "    \"\"\"Main pipeline orchestrator\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize all components\"\"\"\n",
        "        print(\"=\" * 70)\n",
        "        print(\"SEC 10-Q FILING RAG SYSTEM\")\n",
        "        print(\"=\" * 70)\n",
        "\n",
        "        # Ingestion components (these are working perfectly)\n",
        "        self.loader = SECDocumentLoader()\n",
        "        self.processor = DocumentProcessor()\n",
        "        self.qdrant_manager = QdrantManager()\n",
        "\n",
        "        # Query component (to be initialized later)\n",
        "        self.query_engine = None\n",
        "\n",
        "\n",
        "    def load_and_index_filings(self, tickers: List[str] = Config.TICKERS, num_filings_per_ticker: int = 1):\n",
        "        \"\"\"\n",
        "        MODIFIED: This function now only checks if the Golden Set exists.\n",
        "        It does NOT perform indexing.\n",
        "        \"\"\"\n",
        "        print(f\"\\\\n{'=' * 70}\")\n",
        "        print(f\"CHECKING DATABASE: {Config.COLLECTION_NAME}\")\n",
        "        print(f\"{'=' * 70}\")\n",
        "        \n",
        "        try:\n",
        "            count = self.qdrant_manager.client.count(Config.COLLECTION_NAME, exact=True)\n",
        "            if count.count > 0:\n",
        "                print(f\"✓ Collection '{Config.COLLECTION_NAME}' found with {count.count} docs. Proceeding to query.\")\n",
        "            else:\n",
        "                print(f\"✗ ERROR: Collection '{Config.COLLECTION_NAME}' is empty or not found.\")\n",
        "                print(\"Please run '0_build_database.ipynb' first.\")\n",
        "                raise Exception(\"Database not found.\")\n",
        "        except Exception as e:\n",
        "            print(f\"✗ ERROR: Could not connect to or find collection '{Config.COLLECTION_NAME}'.\")\n",
        "            print(\"Please run '0_build_database.ipynb' first.\")\n",
        "            raise e\n",
        "        \n",
        "        print(f\"{'=' * 70}\\\\n\")\n",
        "\n",
        "    def query(self, question: str, ticker_filter: str = None):\n",
        "        \"\"\"\n",
        "        Query the indexed filings using the new MANUAL engine\n",
        "        \"\"\"\n",
        "        if self.query_engine is None:\n",
        "            # Initialize the ManualRAGEngine, passing it the\n",
        "            # processor (for the model) and manager (for search)\n",
        "            self.query_engine = ManualRAGEngine(\n",
        "                document_processor=self.processor,\n",
        "                qdrant_manager=self.qdrant_manager\n",
        "            )\n",
        "\n",
        "        result = self.query_engine.query(question, ticker_filter)\n",
        "\n",
        "        # Print results (this part is the same)\n",
        "        print(f\"\\n{'=' * 70}\")\n",
        "        print(f\"ANSWER\")\n",
        "        print(f\"{'=' * 70}\")\n",
        "        print(f\"\\n{result['answer']}\\n\")\n",
        "\n",
        "        print(f\"{'=' * 70}\")\n",
        "        print(f\"SOURCES ({len(result['sources'])} chunks)\")\n",
        "        print(f\"{'=' * 70}\")\n",
        "        for i, source in enumerate(result['sources'], 1):\n",
        "            print(f\"\\n{i}. {source['company']} ({source['ticker']}) - {source['item']}\")\n",
        "            print(f\"   Filing Date: {source['filing_date']}\")\n",
        "            print(f\"   Relevance Score: {source['score']:.4f}\") # Can now show the real score\n",
        "\n",
        "        print(f\"\\n{'=' * 70}\\\\n\")\n",
        "\n",
        "        return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fb9524b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fb9524b",
        "outputId": "68e39ca6-af07-4360-9353-71f56d4754e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "SEC 10-Q FILING RAG SYSTEM\n",
            "======================================================================\n",
            "\n",
            " Loading embedding model: sentence-transformers/all-MiniLM-L6-v2\n",
            "   ✓ Model loaded (dimension: 384)\n",
            "   ✓ Initialized RecursiveCharacterTextSplitter (chunk: 800, overlap: 200)\n",
            "\n",
            "Connecting to Qdrant Cloud...\n",
            "   ✓ Connected to Qdrant\n",
            "\\n======================================================================\n",
            "CHECKING DATABASE: sec_filings_10q_GOLDEN_BENCHMARK\n",
            "======================================================================\n",
            "✓ Collection 'sec_filings_10q_GOLDEN_BENCHMARK' found with 12807 docs. Proceeding to query.\n",
            "======================================================================\\n\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # ========================================================================\n",
        "    # INITIALIZE PIPELINE\n",
        "    # ========================================================================\n",
        "    pipeline = SECFilingRAGPipeline()\n",
        "\n",
        "    # ========================================================================\n",
        "    # LOAD AND INDEX FILINGS\n",
        "    # ========================================================================\n",
        "    # This will load the latest 10-Q for each company and index them\n",
        "\n",
        "    pipeline.load_and_index_filings(num_filings_per_ticker=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0aa8ad26",
      "metadata": {
        "id": "0aa8ad26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running 6 queries...\n",
            "\n",
            "--- Running Query: What are the main risk factors mentioned by each companies? ---\n",
            "\n",
            " Initializing Manual RAG Query Engine...\n",
            "   ✓ Using existing embedding model from DocumentProcessor\n",
            "   ✓ Using existing QdrantManager for search\n",
            "   ✓ Initialized ChatOpenAI LLM\n",
            "   ✓ Manual RAG Engine ready.\n",
            "\n",
            " Processing query with Manual Engine: 'What are the main risk factors mentioned by each companies?'\n",
            "   → Manually embedding query...\n",
            "   → Manually searching Qdrant...\n",
            "   → Formatting context and building prompt...\n",
            "   → Sending prompt to LLM...\n",
            "\n",
            "======================================================================\n",
            "ANSWER\n",
            "======================================================================\n",
            "\n",
            "According to the provided context, the main risk factors mentioned by each company are as follows:\n",
            "\n",
            "**AMD (Sources 1 and 2, Item 1A):**\n",
            "- The markets in which AMD's products are sold are highly competitive and rapidly evolving.\n",
            "- The semiconductor industry is highly cyclical and has experienced severe downturns.\n",
            "\n",
            "**Apple (Source 3, Item 1A):**\n",
            "- The company's business, reputation, results of operations, financial condition, and stock price can be affected by various factors as outlined in their 2024 Form 10-K, and there have been no material changes to the risk factors since then as per the provided context.\n",
            "\n",
            "**Amazon (Sources 4 and 5, Item 1A):**\n",
            "- The difficulty in implementing appropriate controls, procedures, and policies at acquired companies suitable for a larger public company.\n",
            "- Risks associated with businesses acquired or invested in, which may differ from or be more significant than those faced by other businesses.\n",
            "- Potential unknown liabilities associated with an acquired company or investment.\n",
            "- For foreign transactions, additional risks related to the integration of operations across different cultures and languages, and the economic, political, and regulatory risks associated with specific countries.\n",
            "\n",
            "======================================================================\n",
            "SOURCES (5 chunks)\n",
            "======================================================================\n",
            "\n",
            "1. ADVANCED MICRO DEVICES INC (AMD) - ITEM 1A\n",
            "   Filing Date: 2025-11-05\n",
            "   Relevance Score: 0.6942\n",
            "\n",
            "2. ADVANCED MICRO DEVICES INC (AMD) - ITEM 1A\n",
            "   Filing Date: 2025-08-06\n",
            "   Relevance Score: 0.6942\n",
            "\n",
            "3. Apple Inc. (AAPL) - ITEM 1A\n",
            "   Filing Date: 2025-01-31\n",
            "   Relevance Score: 0.6650\n",
            "\n",
            "4. AMAZON COM INC (AMZN) - ITEM 1A\n",
            "   Filing Date: 2025-08-01\n",
            "   Relevance Score: 0.6644\n",
            "\n",
            "5. AMAZON COM INC (AMZN) - ITEM 1A\n",
            "   Filing Date: 2025-05-02\n",
            "   Relevance Score: 0.6644\n",
            "\n",
            "======================================================================\\n\n",
            "\n",
            "--- Running Query: What risks did Apple disclose in their latest 10-Q? ---\n",
            "\n",
            " Processing query with Manual Engine: 'What risks did Apple disclose in their latest 10-Q?'\n",
            "   → Manually embedding query...\n",
            "   → Manually searching Qdrant...\n",
            "   → Formatting context and building prompt...\n",
            "   → Sending prompt to LLM...\n",
            "\n",
            "======================================================================\n",
            "ANSWER\n",
            "======================================================================\n",
            "\n",
            "Based on the provided context, Apple did not report any new material changes to their risk factors in the latest 10-Q. They refer to the risk factors discussed in their previous filings. According to the information, risks that impact Apple include macroeconomic conditions such as inflation, interest rates, and currency fluctuations, which could materially impact the company’s results of operations and financial condition (Source 2, AAPL - ITEM 2). Furthermore, events that can disrupt the supply chain, cause slowdowns in service offerings, and increase costs are also highlighted as risks (Source 4, AAPL - ITEM 1A).\n",
            "\n",
            "For a detailed list of risk factors, it is suggested to refer to Part I, Item 1A of the 2024 Form 10-K and Part II, Item 1A of the current Form 10-Q as discussed in Source 3, AAPL - ITEM 2. However, specific descriptions of these risks from the 10-Q are not provided in the context.\n",
            "\n",
            "======================================================================\n",
            "SOURCES (5 chunks)\n",
            "======================================================================\n",
            "\n",
            "1. Apple Inc. (AAPL) - ITEM 1A\n",
            "   Filing Date: 2024-08-02\n",
            "   Relevance Score: 0.7313\n",
            "\n",
            "2. Apple Inc. (AAPL) - ITEM 2\n",
            "   Filing Date: 2025-05-02\n",
            "   Relevance Score: 0.6400\n",
            "\n",
            "3. Apple Inc. (AAPL) - ITEM 2\n",
            "   Filing Date: 2025-05-02\n",
            "   Relevance Score: 0.6190\n",
            "\n",
            "4. Apple Inc. (AAPL) - ITEM 1A\n",
            "   Filing Date: 2025-05-02\n",
            "   Relevance Score: 0.6020\n",
            "\n",
            "5. Apple Inc. (AAPL) - ITEM 1\n",
            "   Filing Date: 2024-08-02\n",
            "   Relevance Score: 0.5975\n",
            "\n",
            "======================================================================\\n\n",
            "\n",
            "--- Running Query: Compare the revenue trends of NVIDIA and AMD ---\n",
            "\n",
            " Processing query with Manual Engine: 'Compare the revenue trends of NVIDIA and AMD'\n",
            "   → Manually embedding query...\n",
            "   → Manually searching Qdrant...\n",
            "   → Formatting context and building prompt...\n",
            "   → Sending prompt to LLM...\n",
            "\n",
            "======================================================================\n",
            "ANSWER\n",
            "======================================================================\n",
            "\n",
            "Based on the provided context, NVIDIA's revenue trends are characterized by significant contributions from specific customers in the Compute & Networking segment. According to Source 1 and Source 2, one customer represented 17% and 13% of total revenue for the second quarter and first half of fiscal year 2024, respectively. In the third quarter, a different customer accounted for 12% of total revenue, and yet another customer accounted for 11% of total revenue for the first nine months of fiscal year 2024, both attributable to the Compute & Networking segment.\n",
            "\n",
            "For AMD, as per Source 5, there is a reported 36% increase in net revenue for the three months ended March 29, 2025, compared to the prior year period. This increase is primarily driven by growth in the Data Center segment, notably due to sales of AMD EPYC™ CPUs and AMD Instinct™ GPUs, as well as growth in the combined Client and Gaming segment which benefited from strong demand for \"Zen 5\" AMD Ryzen™ processors. However, this was partially offset by decreased semi-custom revenue.\n",
            "\n",
            "In summary, both companies show positive revenue trends in their respective high-demand segments, with NVIDIA having significant contributions from key customers and AMD experiencing robust growth in its Data Center and Client and Gaming segments.\n",
            "\n",
            "======================================================================\n",
            "SOURCES (5 chunks)\n",
            "======================================================================\n",
            "\n",
            "1. NVIDIA CORP (NVDA) - ITEM 1\n",
            "   Filing Date: 2024-08-28\n",
            "   Relevance Score: 0.6962\n",
            "\n",
            "2. NVIDIA CORP (NVDA) - ITEM 1\n",
            "   Filing Date: 2024-11-20\n",
            "   Relevance Score: 0.6546\n",
            "\n",
            "3. NVIDIA CORP (NVDA) - ITEM 1\n",
            "   Filing Date: 2024-11-20\n",
            "   Relevance Score: 0.6414\n",
            "\n",
            "4. NVIDIA CORP (NVDA) - ITEM 1\n",
            "   Filing Date: 2024-08-28\n",
            "   Relevance Score: 0.6392\n",
            "\n",
            "5. ADVANCED MICRO DEVICES INC (AMD) - ITEM 2\n",
            "   Filing Date: 2025-05-07\n",
            "   Relevance Score: 0.6338\n",
            "\n",
            "======================================================================\\n\n",
            "\n",
            "--- Running Query: What was Tesla's R&D spending in the latest quarter? ---\n",
            "\n",
            " Processing query with Manual Engine: 'What was Tesla's R&D spending in the latest quarter?'\n",
            "   → Manually embedding query...\n",
            "   → Manually searching Qdrant...\n",
            "   → Formatting context and building prompt...\n",
            "   → Sending prompt to LLM...\n",
            "\n",
            "======================================================================\n",
            "ANSWER\n",
            "======================================================================\n",
            "\n",
            "The specific amount of Tesla's R&D spending in the latest quarter is not provided in the context. The context mentions percentage changes and reasons for those changes, but it does not specify the actual dollar amount spent on R&D in the latest quarter.\n",
            "\n",
            "======================================================================\n",
            "SOURCES (5 chunks)\n",
            "======================================================================\n",
            "\n",
            "1. Tesla, Inc. (TSLA) - ITEM 2\n",
            "   Filing Date: 2024-10-24\n",
            "   Relevance Score: 0.5818\n",
            "\n",
            "2. Tesla, Inc. (TSLA) - ITEM 2\n",
            "   Filing Date: 2025-10-23\n",
            "   Relevance Score: 0.5687\n",
            "\n",
            "3. Tesla, Inc. (TSLA) - ITEM 2\n",
            "   Filing Date: 2025-07-24\n",
            "   Relevance Score: 0.5555\n",
            "\n",
            "4. Tesla, Inc. (TSLA) - ITEM 2\n",
            "   Filing Date: 2024-10-24\n",
            "   Relevance Score: 0.5433\n",
            "\n",
            "5. Alphabet Inc. (GOOGL) - ITEM 2\n",
            "   Filing Date: 2025-04-25\n",
            "   Relevance Score: 0.5425\n",
            "\n",
            "======================================================================\\n\n",
            "\n",
            "--- Running Query: How has Microsoft's operating income changed over the last year? ---\n",
            "\n",
            " Processing query with Manual Engine: 'How has Microsoft's operating income changed over the last year?'\n",
            "   → Manually embedding query...\n",
            "   → Manually searching Qdrant...\n",
            "   → Formatting context and building prompt...\n",
            "   → Sending prompt to LLM...\n",
            "\n",
            "======================================================================\n",
            "ANSWER\n",
            "======================================================================\n",
            "\n",
            "The provided context does not contain any information about Microsoft's operating income.\n",
            "\n",
            "======================================================================\n",
            "SOURCES (5 chunks)\n",
            "======================================================================\n",
            "\n",
            "1. AMAZON COM INC (AMZN) - ITEM 2\n",
            "   Filing Date: 2025-08-01\n",
            "   Relevance Score: 0.5818\n",
            "\n",
            "2. AMAZON COM INC (AMZN) - ITEM 2\n",
            "   Filing Date: 2024-11-01\n",
            "   Relevance Score: 0.5781\n",
            "\n",
            "3. AMAZON COM INC (AMZN) - ITEM 2\n",
            "   Filing Date: 2025-05-02\n",
            "   Relevance Score: 0.5744\n",
            "\n",
            "4. Alphabet Inc. (GOOGL) - ITEM 2\n",
            "   Filing Date: 2025-10-30\n",
            "   Relevance Score: 0.5671\n",
            "\n",
            "5. ADVANCED MICRO DEVICES INC (AMD) - ITEM 2\n",
            "   Filing Date: 2024-10-30\n",
            "   Relevance Score: 0.5590\n",
            "\n",
            "======================================================================\\n\n",
            "\n",
            "--- Running Query: What was the gross profit margin for all companies? ---\n",
            "\n",
            " Processing query with Manual Engine: 'What was the gross profit margin for all companies?'\n",
            "   → Manually embedding query...\n",
            "   → Manually searching Qdrant...\n",
            "   → Formatting context and building prompt...\n",
            "   → Sending prompt to LLM...\n",
            "\n",
            "======================================================================\n",
            "ANSWER\n",
            "======================================================================\n",
            "\n",
            "Based on the provided context:\n",
            "\n",
            "- **TSLA (Tesla)**:\n",
            "  - Source 1: Total gross margin was 18.0% and 19.8%.\n",
            "  - Source 2: Total gross margin was 19.8% and 17.9%.\n",
            "  - Source 3: Total gross margin was 17.2% and 18.0%.\n",
            "\n",
            "- **NVDA (NVIDIA)**:\n",
            "  - Source 4: Gross margin was 75.1% for the second quarter and 76.6% for the first half of fiscal year 2025.\n",
            "\n",
            "- **ORCL (Oracle)**:\n",
            "  - Source 5 does not provide specific figures for gross profit margin, as it mentions that the margins reflect only the direct controllable costs and do not include certain allocations and expenses.\n",
            "\n",
            "Thus, the gross profit margins provided are 18.0% to 19.8% for Tesla across various sources and periods, and 75.1% to 76.6% for NVIDIA for the specified periods. Oracle's specific gross profit margin is not detailed in the provided context.\n",
            "\n",
            "======================================================================\n",
            "SOURCES (5 chunks)\n",
            "======================================================================\n",
            "\n",
            "1. Tesla, Inc. (TSLA) - ITEM 2\n",
            "   Filing Date: 2025-10-23\n",
            "   Relevance Score: 0.6704\n",
            "\n",
            "2. Tesla, Inc. (TSLA) - ITEM 2\n",
            "   Filing Date: 2024-10-24\n",
            "   Relevance Score: 0.6659\n",
            "\n",
            "3. Tesla, Inc. (TSLA) - ITEM 2\n",
            "   Filing Date: 2025-07-24\n",
            "   Relevance Score: 0.6528\n",
            "\n",
            "4. NVIDIA CORP (NVDA) - ITEM 2\n",
            "   Filing Date: 2024-08-28\n",
            "   Relevance Score: 0.6454\n",
            "\n",
            "5. ORACLE CORP (ORCL) - ITEM 1\n",
            "   Filing Date: 2024-09-10\n",
            "   Relevance Score: 0.6310\n",
            "\n",
            "======================================================================\\n\n",
            "\n",
            "--- All queries complete. Saving all results to: data\\base_RAG_results.json ---\n",
            "✓ Successfully saved all answers.\n",
            "\n",
            "Pipeline run finished.\n"
          ]
        }
      ],
      "source": [
        "# =======================================================================\n",
        "# DEFINE QUESTIONS AND SAVE ALL ANSWERS TO ONE FILE\n",
        "# =======================================================================\n",
        "\n",
        "# Define the output folder\n",
        "DATA_FOLDER = \"data\"\n",
        "if not os.path.exists(DATA_FOLDER):\n",
        "    os.makedirs(DATA_FOLDER)\n",
        "    print(f\"Created data folder: {DATA_FOLDER}\")\n",
        "\n",
        "# Define the list of questions to run\n",
        "queries_to_run = [\n",
        "    {\n",
        "        \"question\": \"What are the main risk factors mentioned by each companies?\",\n",
        "        \"ticker_filter\": None,\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"What risks did Apple disclose in their latest 10-Q?\",\n",
        "        \"ticker_filter\": None,\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Compare the revenue trends of NVIDIA and AMD\",\n",
        "        \"ticker_filter\": None,\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"What was Tesla's R&D spending in the latest quarter?\",\n",
        "        \"ticker_filter\": None,\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"How has Microsoft's operating income changed over the last year?\",\n",
        "        \"ticker_filter\": None,\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"What was the gross profit margin for all companies?\",\n",
        "        \"ticker_filter\": None,\n",
        "    },\n",
        "]\n",
        "\n",
        "print(f\"\\nRunning {len(queries_to_run)} queries...\")\n",
        "\n",
        "# This list will hold all the results\n",
        "all_results = []\n",
        "\n",
        "for query in queries_to_run:\n",
        "    print(f\"\\n--- Running Query: {query['question']} ---\")\n",
        "    \n",
        "    # Run the query and get the result\n",
        "    # This works because the 'pipeline' variable still exists in memory!\n",
        "    result = pipeline.query(\n",
        "        question=query[\"question\"],\n",
        "        ticker_filter=query[\"ticker_filter\"]\n",
        "    )\n",
        "    \n",
        "    # Create a dictionary for this query and its result\n",
        "    query_output = {\n",
        "        \"question\": query[\"question\"],\n",
        "        \"ticker_filter\": query[\"ticker_filter\"],\n",
        "        \"response\": result  # The 'result' dict contains 'answer' and 'sources'\n",
        "    }\n",
        "    \n",
        "    # Add the output to our main list\n",
        "    all_results.append(query_output)\n",
        "\n",
        "# After all queries are done, save the entire list to one file\n",
        "save_path = os.path.join(DATA_FOLDER, \"base_RAG_results.json\")\n",
        "print(f\"\\n--- All queries complete. Saving all results to: {save_path} ---\")\n",
        "\n",
        "try:\n",
        "    with open(save_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(all_results, f, indent=4)\n",
        "    print(f\"✓ Successfully saved all answers.\")\n",
        "except Exception as e:\n",
        "    print(f\"✗ Failed to save results: {e}\")\n",
        "\n",
        "print(\"\\nPipeline run finished.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
