{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install sec_api\n",
        "!pip install requests beautifulsoup4 lxml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FQpq-0-Yfpi",
        "outputId": "80bb6e92-c02c-43e2-d600-7ec259950b2d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sec_api\n",
            "  Downloading sec_api-1.0.32-py3-none-any.whl.metadata (66 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/66.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from sec_api) (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->sec_api) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->sec_api) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->sec_api) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->sec_api) (2025.10.5)\n",
            "Downloading sec_api-1.0.32-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: sec_api\n",
            "Successfully installed sec_api-1.0.32\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.5)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (5.4.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.10.5)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (4.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsouQX4zqa8Q",
        "outputId": "a15c6601-1efb-4868-8616-921235f08832"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Fetching CIK for ticker: GOOGL...\n",
            "   Found CIK: 0001652044\n",
            "2. Fetching submission history from SEC EDGAR...\n",
            "   Found latest 10-Q filed on: 2025-07-24\n",
            "3. Fetching 10-Q document from: https://www.sec.gov/Archives/edgar/data/0001652044/000165204425000062/goog-20250630.htm\n",
            "   Successfully fetched document.\n",
            "4. Parsing HTML content...\n",
            "   Parsing complete.\n",
            "\n",
            "--- 10-Q Report Summary ---\n",
            "\n",
            "====================\n",
            "PART I\n",
            "====================\n",
            "\n",
            "--- ITEM 1 ---\n",
            "ITEM 1.\n",
            "FINANCIAL STATEMENTS\n",
            "Alphabet Inc.\n",
            "CONSOLIDATED BALANCE SHEETS\n",
            "(in millions, except par value per share amounts)\n",
            "\n",
            "|  | As ofDecember 31, 2024 |  | As ofJune 30, 2025 |\n",
            "| --- | --- | --- | --- |\n",
            "|  |  |  | (unaudited) |\n",
            "| Assets |  |  |  |\n",
            "| Current assets: |  |  |  |\n",
            "| Cash and cash equivalents | $ | 23,466 |  |\n",
            "| Marketable securities | 72,191 |  |  |\n",
            "| Total cash, cash equivalents, and marketable securities | 95,657 |  |  |\n",
            "| Accounts receivable, net | 52,340 |  |  |\n",
            "| Other current as...\n",
            "\n",
            "--- ITEM 2 ---\n",
            "ITEM 2.\n",
            "MANAGEMENT’S DISCUSSION AND ANALYSIS OF FINANCIAL CONDITION AND RESULTS OF OPERATIONS\n",
            "Please read the following discussion and analysis of our financial condition and results of operations together with \"Note About Forward-Looking Statements\" and our consolidated financial statements and related notes included under Item 1 of this Quarterly Report on Form 10-Q as well as our Annual Report on Form 10-K for the fiscal year ended December 31, 2024, including Part I, Item 1A \"Risk Factors.\"...\n",
            "\n",
            "--- ITEM 3 ---\n",
            "ITEM 3.\n",
            "QUANTITATIVE AND QUALITATIVE DISCLOSURES ABOUT MARKET RISK\n",
            "For quantitative and qualitative disclosures about market risk, refer to Part II, Item 7A, Quantitative and Qualitative Disclosures About Market Risk, in our Annual Report on Form 10-K for the year ended December 31, 2024.\n",
            "50...\n",
            "\n",
            "--- ITEM 4 ---\n",
            "ITEM 4.\n",
            "CONTROLS AND PROCEDURES\n",
            "Evaluation of Disclosure Controls and Procedures\n",
            "Our management, with the participation of our chief executive officer and chief financial officer, evaluated the effectiveness of our disclosure controls and procedures pursuant to Rule 13a-15 under the Exchange Act, as of the end of the period covered by this Quarterly Report on Form 10-Q.\n",
            "Based on this evaluation, our chief executive officer and chief financial officer concluded that, as of June 30, 2025, our disc...\n",
            "\n",
            "====================\n",
            "PART II\n",
            "====================\n",
            "\n",
            "--- ITEM 1 ---\n",
            "ITEM 1.\n",
            "LEGAL PROCEEDINGS\n",
            "For a description of our material pending legal proceedings, see Note 10 “Commitments and Contingencies - Legal Matters” of the Notes to Consolidated Financial Statements included in Part I, Item 1 of this Quarterly Report on Form 10-Q, which is incorporated herein by reference....\n",
            "\n",
            "--- ITEM 1A ---\n",
            "ITEM 1A.\n",
            "RISK FACTORS\n",
            "Our operations and financial results are subject to various risks and uncertainties, including but not limited to those described in Part I, Item 1A, \"Risk Factors\" in our Annual Report on Form 10-K for the year ended December 31, 2024, which could harm our business, reputation, financial condition, and operating results, and affect the trading price of our Class A and Class C stock.\n",
            "For additional information about the ongoing material legal proceedings to which we are sub...\n",
            "\n",
            "--- ITEM 2 ---\n",
            "ITEM 2.\n",
            "UNREGISTERED SALES OF EQUITY SECURITIES AND USE OF PROCEEDS\n",
            "Issuer Purchases of Equity Securities\n",
            "The following table presents information with respect to Alphabet's repurchases of Class A and Class C stock during the quarter ended June 30, 2025.\n",
            "\n",
            "| Period |  | Total Number of Class A Shares Purchased(in thousands)(1) |  | Total Number of Class C Shares Purchased(in thousands)(1) |  | Average Price Paid per Class A Share(2) |  | Average Price Paid per Class C Share(2) |  | Total Number o...\n",
            "\n",
            "--- ITEM 5 ---\n",
            "ITEM 5.\n",
            "OTHER INFORMATION\n",
            "10b5-1 Trading Plans\n",
            "During the quarter ended June 30, 2025, the following Section 16 officers adopted, modified, or terminated a “Rule 10b5-1 trading arrangement” (as defined in Item 408 of Regulation S-K of the Exchange Act).\n",
            "•\n",
            "Amie Thuener O’Toole\n",
            ",\n",
            "Vice President, Corporate Controller and Principal Accounting Officer\n",
            ",\n",
            "terminated\n",
            "a trading plan on\n",
            "April 10, 2025\n",
            "that was originally entered into on May 31, 2024. She\n",
            "adopted\n",
            "a new trading plan on\n",
            "May 23, 2025\n",
            "(with th...\n",
            "\n",
            "--- ITEM 6 ---\n",
            "ITEM 6.\n",
            "EXHIBITS\n",
            "\n",
            "| ExhibitNumber |  |  | Description |  | Incorporated by reference herein |\n",
            "| --- | --- | --- | --- | --- | --- |\n",
            "|  |  | Form |  | Date |  |\n",
            "| 4.01 |  |  | Indenture, dated February 12, 2016, between the Registrant and The Bank of New York Mellon Trust Company, N.A., as Trustee |  | Registration Statement on Form S-3 (File No. 333-209510) |\n",
            "| 4.02 |  |  | Form of Global Note representing the Registrant’s 2.500% notes due 2029 |  | Current Report on Form 8-K(File No. 001-37580)...\n",
            "\n",
            "--- End of Summary ---\n"
          ]
        }
      ],
      "source": [
        "# Final version\n",
        "\n",
        "import requests\n",
        "import re\n",
        "from bs4 import BeautifulSoup, NavigableString\n",
        "from collections import defaultdict\n",
        "\n",
        "# --- Configuration ---\n",
        "# The SEC EDGAR API requires a custom User-Agent header.\n",
        "# Replace 'YourAppName' and 'youremail@example.com' with your information.\n",
        "HEADERS = {'User-Agent': 'YourAppName youremail@example.com'}\n",
        "# CIK mapping file URL from the SEC\n",
        "CIK_MAP_URL = 'https://www.sec.gov/files/company_tickers.json'\n",
        "\n",
        "def get_latest_10q(ticker: str) -> str:\n",
        "    \"\"\"\n",
        "    Fetches the HTML content of the latest 10-Q filing for a given stock ticker.\n",
        "\n",
        "    Args:\n",
        "        ticker: The stock ticker symbol (e.g., 'AAPL', 'MSFT').\n",
        "\n",
        "    Returns:\n",
        "        The HTML content of the latest 10-Q filing as a string.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If the ticker is not found or no 10-Q filing is available.\n",
        "        requests.exceptions.RequestException: For network-related errors.\n",
        "    \"\"\"\n",
        "    print(f\"1. Fetching CIK for ticker: {ticker}...\")\n",
        "    # Get the CIK mapping from the SEC\n",
        "    response = requests.get(CIK_MAP_URL, headers=HEADERS)\n",
        "    response.raise_for_status()\n",
        "    company_data = response.json()\n",
        "\n",
        "    # Find the CIK for the given ticker\n",
        "    cik = None\n",
        "    for company in company_data.values():\n",
        "        if company['ticker'] == ticker.upper():\n",
        "            cik = str(company['cik_str']).zfill(10)\n",
        "            break\n",
        "\n",
        "    if not cik:\n",
        "        raise ValueError(f\"Ticker '{ticker}' not found in SEC CIK mapping.\")\n",
        "\n",
        "    print(f\"   Found CIK: {cik}\")\n",
        "\n",
        "    # Fetch the company's submission history\n",
        "    print(\"2. Fetching submission history from SEC EDGAR...\")\n",
        "    submissions_url = f\"https://data.sec.gov/submissions/CIK{cik}.json\"\n",
        "    response = requests.get(submissions_url, headers=HEADERS)\n",
        "    response.raise_for_status()\n",
        "    submissions = response.json()\n",
        "\n",
        "    # Find the latest 10-Q filing\n",
        "    latest_10q = None\n",
        "    for i, form in enumerate(submissions['filings']['recent']['form']):\n",
        "        if form == '10-Q':\n",
        "            accession_number = submissions['filings']['recent']['accessionNumber'][i]\n",
        "            primary_document = submissions['filings']['recent']['primaryDocument'][i]\n",
        "            filing_date = submissions['filings']['recent']['filingDate'][i]\n",
        "            latest_10q = {\n",
        "                'accession_number': accession_number.replace('-', ''),\n",
        "                'primary_document': primary_document,\n",
        "                'date': filing_date\n",
        "            }\n",
        "            break\n",
        "\n",
        "    if not latest_10q:\n",
        "        raise ValueError(f\"No recent 10-Q filings found for ticker '{ticker}'.\")\n",
        "\n",
        "    print(f\"   Found latest 10-Q filed on: {latest_10q['date']}\")\n",
        "\n",
        "    # Construct the URL for the 10-Q HTML document\n",
        "    filing_url = (\n",
        "        f\"https://www.sec.gov/Archives/edgar/data/{cik}/\"\n",
        "        f\"{latest_10q['accession_number']}/{latest_10q['primary_document']}\"\n",
        "    )\n",
        "\n",
        "    # Fetch the filing's HTML content\n",
        "    print(f\"3. Fetching 10-Q document from: {filing_url}\")\n",
        "    response = requests.get(filing_url, headers=HEADERS)\n",
        "    response.raise_for_status()\n",
        "\n",
        "    print(\"   Successfully fetched document.\")\n",
        "    return response.text\n",
        "\n",
        "def _normalize_header_text(text: str) -> str | None:\n",
        "    \"\"\"Normalizes header text to a standard format (e.g., 'PART I', 'ITEM 1A').\"\"\"\n",
        "    text = text.strip().upper()\n",
        "\n",
        "    # Match \"PART I\" or \"PART II\"\n",
        "    part_match = re.search(r'^\\s*(PART\\s+I{1,2})', text)\n",
        "    if part_match:\n",
        "        return re.sub(r'\\s+', ' ', part_match.group(1))\n",
        "\n",
        "    # Match \"ITEM 1\", \"ITEM 1A\", etc.\n",
        "    item_match = re.search(r'^\\s*(ITEM\\s+\\d[A-Z]?)', text)\n",
        "    if item_match:\n",
        "        return re.sub(r'\\s+', ' ', item_match.group(1))\n",
        "\n",
        "    return None\n",
        "\n",
        "def _parse_html_table(table_tag: BeautifulSoup) -> str:\n",
        "    \"\"\"Converts a BeautifulSoup table Tag into a Markdown formatted string.\"\"\"\n",
        "    markdown_rows = []\n",
        "\n",
        "    # Process all rows in the table\n",
        "    for tr in table_tag.find_all('tr'):\n",
        "        # Get all cells (th and td) in the row, clean up whitespace and newlines\n",
        "        cells = [\" \".join(cell.get_text(strip=True).split()) for cell in tr.find_all(['td', 'th'])]\n",
        "        if any(cells):  # Only add rows that have some content\n",
        "            markdown_rows.append(cells)\n",
        "\n",
        "    if not markdown_rows:\n",
        "        return \"\"\n",
        "\n",
        "    # Convert rows to Markdown table format\n",
        "    md_output = []\n",
        "    # Header row\n",
        "    header = markdown_rows[0]\n",
        "    md_output.append(\"| \" + \" | \".join(header) + \" |\")\n",
        "    # Separator\n",
        "    md_output.append(\"| \" + \" | \".join(['---'] * len(header)) + \" |\")\n",
        "    # Body rows\n",
        "    for row in markdown_rows[1:]:\n",
        "        # Pad row if it has fewer columns than the header (handles simple colspan)\n",
        "        while len(row) < len(header):\n",
        "            row.append(\"\")\n",
        "        # Truncate if it has more (rare)\n",
        "        row = row[:len(header)]\n",
        "        md_output.append(\"| \" + \" | \".join(row) + \" |\")\n",
        "\n",
        "    return \"\\n\" + \"\\n\".join(md_output) + \"\\n\"\n",
        "\n",
        "\n",
        "def parse_10q(html_content: str) -> dict:\n",
        "    \"\"\"\n",
        "    Parses the HTML of a 10-Q filing to extract Parts and Items.\n",
        "\n",
        "    Args:\n",
        "        html_content: The HTML content of the 10-Q filing.\n",
        "\n",
        "    Returns:\n",
        "        A dictionary structured with Parts and Items of the 10-Q report.\n",
        "    \"\"\"\n",
        "    print(\"4. Parsing HTML content...\")\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "    # Find all potential header elements in the document\n",
        "    potential_headers = soup.find_all(['p', 'b', 'strong', 'div'])\n",
        "\n",
        "    # Filter for valid headers, ignoring table of contents links.\n",
        "    # We no longer enforce uniqueness here to handle documents where headers\n",
        "    # appear in a TOC and then again in the body.\n",
        "    doc_headers = []\n",
        "    for header in potential_headers:\n",
        "        text = header.get_text(strip=True)\n",
        "        if len(text) > 100:  # Skip long paragraphs\n",
        "            continue\n",
        "\n",
        "        normalized_key = _normalize_header_text(text)\n",
        "        if normalized_key:\n",
        "            # Ignore headers that are part of a link (likely TOC)\n",
        "            if not header.find_parent('a'):\n",
        "                doc_headers.append({'tag': header, 'key': normalized_key})\n",
        "\n",
        "    if not doc_headers:\n",
        "        print(\"   Warning: Could not find any standard Part/Item headers.\")\n",
        "        return {}\n",
        "\n",
        "    parsed_data = defaultdict(lambda: defaultdict(str))\n",
        "    current_part_key = None\n",
        "\n",
        "    for i, header_info in enumerate(doc_headers):\n",
        "        current_key = header_info['key']\n",
        "\n",
        "        if 'PART' in current_key:\n",
        "            current_part_key = current_key\n",
        "            continue\n",
        "\n",
        "        if 'ITEM' in current_key:\n",
        "            if not current_part_key:\n",
        "                current_part_key = \"PART I\" # Default to Part I if an item appears first\n",
        "\n",
        "            start_node = header_info['tag']\n",
        "            end_node = doc_headers[i + 1]['tag'] if i + 1 < len(doc_headers) else None\n",
        "\n",
        "            content_parts = []\n",
        "            element = start_node.next_element\n",
        "\n",
        "            while element and element != end_node:\n",
        "                # If it's text, add it, but only if it's not inside a table.\n",
        "                if isinstance(element, NavigableString):\n",
        "                    if not element.find_parent('table'):\n",
        "                        text = element.strip()\n",
        "                        if text:\n",
        "                            content_parts.append(text)\n",
        "\n",
        "                # If it's a table, parse it as a whole unit, but only if it's not nested.\n",
        "                elif element.name == 'table':\n",
        "                    if not element.find_parent('table'):\n",
        "                         table_markdown = _parse_html_table(element)\n",
        "                         if table_markdown:\n",
        "                            content_parts.append(table_markdown)\n",
        "\n",
        "                element = element.next_element\n",
        "\n",
        "            # Join content with newlines to preserve table formatting\n",
        "            full_content = \"\\n\".join(content_parts)\n",
        "            # Collapse excess newlines but preserve paragraph breaks\n",
        "            clean_content = re.sub(r'\\n{3,}', '\\n\\n', full_content).strip()\n",
        "\n",
        "            # Overwrite content for the key. This ensures the version from the\n",
        "            # document body (which comes later and has content) replaces any\n",
        "            # entry from the table of contents.\n",
        "            parsed_data[current_part_key][current_key] = clean_content\n",
        "\n",
        "    print(\"   Parsing complete.\")\n",
        "    # Convert defaultdicts to regular dicts for cleaner output\n",
        "    return {part: dict(items) for part, items in parsed_data.items()}\n",
        "\n",
        "\n",
        "def print_10q_summary(parsed_data: dict, content_length: int = 500):\n",
        "    \"\"\"\n",
        "    Prints a summary of the parsed 10-Q data.\n",
        "\n",
        "    Args:\n",
        "        parsed_data: The dictionary returned by the parse_10q function.\n",
        "        content_length: The number of characters to display for each item's content.\n",
        "    \"\"\"\n",
        "    print(\"\\n--- 10-Q Report Summary ---\")\n",
        "    if not parsed_data:\n",
        "        print(\"No data was parsed from the document.\")\n",
        "        return\n",
        "\n",
        "    # Sort parts (Part I before Part II)\n",
        "    sorted_parts = sorted(parsed_data.keys())\n",
        "\n",
        "    for part in sorted_parts:\n",
        "        items = parsed_data[part]\n",
        "        print(f\"\\n====================\\n{part}\\n====================\")\n",
        "        if not items:\n",
        "            print(\"  (No items found for this part)\")\n",
        "            continue\n",
        "\n",
        "        # Sort items numerically/alphabetically (Item 1, Item 1A, Item 2)\n",
        "        sorted_items = sorted(items.keys(), key=lambda x: (int(re.search(r'\\d+', x).group()), x))\n",
        "\n",
        "        for item in sorted_items:\n",
        "            content = items[item]\n",
        "            print(f\"\\n--- {item} ---\")\n",
        "            summary = content[:content_length].strip()\n",
        "            if not summary:\n",
        "                print(\"  (No content extracted for this item)\")\n",
        "            else:\n",
        "                print(f\"{summary}...\")\n",
        "    print(\"\\n--- End of Summary ---\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # --- Main Execution ---\n",
        "    # Specify the ticker you want to analyze\n",
        "    target_ticker = 'GOOGL' # You can change this to 'MSFT', 'GOOGL', etc.\n",
        "\n",
        "    try:\n",
        "        # Step 1: Get the latest 10-Q filing's HTML\n",
        "        html = get_latest_10q(target_ticker)\n",
        "\n",
        "        # Step 2: Parse the HTML into a structured dictionary\n",
        "        report_data = parse_10q(html)\n",
        "\n",
        "        # Step 3: Print a summary of the parsed content\n",
        "        print_10q_summary(report_data)\n",
        "\n",
        "    except ValueError as e:\n",
        "        print(f\"\\nError: {e}\")\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"\\nNetwork Error: Failed to fetch data from the SEC. Details: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nAn unexpected error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "report_data['PART II']['ITEM 2']"
      ],
      "metadata": {
        "collapsed": true,
        "id": "pl_FYD1ezwl9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "f30e0253-6952-4faa-d2f2-e71567dba3a4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"ITEM 2.\\nUNREGISTERED SALES OF EQUITY SECURITIES AND USE OF PROCEEDS\\nIssuer Purchases of Equity Securities\\nThe following table presents information with respect to Alphabet's repurchases of Class A and Class C stock during the quarter ended June\\xa030, 2025.\\n\\n| Period |  | Total Number of Class A Shares Purchased(in thousands)(1) |  | Total Number of Class C Shares Purchased(in thousands)(1) |  | Average Price Paid per Class A Share(2) |  | Average Price Paid per Class C Share(2) |  | Total Number of Shares Purchased as Part of Publicly Announced Programs(in thousands)(1) |  | Approximate Dollar Value of Shares that May Yet Be Purchased Under the Program(in millions) |\\n| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\\n| April 1 - 30 |  | 8,471 |  |  | 24,689 |  |  | $ | 155.60 |  |  | $ |\\n| May 1 - 31 |  | 4,529 |  |  | 22,447 |  |  | $ | 164.95 |  |  | $ |\\n| June 1 - 30 |  | 2,710 |  |  | 17,853 |  |  | $ | 174.18 |  |  | $ |\\n| Total |  | 15,710 |  |  | 64,989 |  |  |  |  |  |  | 80,699 |\\n\\n(1)\\nRepurchases are being executed from time to time, subject to general business and market conditions and other investment opportunities, through open market purchases or privately negotiated transactions, including through Rule 10b5-1 plans. The repurchase program does not have an expiration date. For additional information related to share repurchases, see Note 11 of the Notes to Consolidated Financial Statements included in Part I, Item 1 of this Quarterly Report on Form 10-Q.\\n(2)\\nAverage price paid per share includes costs associated with the repurchases.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wkvcv1yvqkWq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WPADddl7qkaR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pOTYl5REqkch"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2svslbPJqkec"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ymk_O_FTqkgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mytKaU8IqkjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2SmKfK2Dqklg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Bw0Q2Ad6qknk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JmqLmN9gqkp4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}